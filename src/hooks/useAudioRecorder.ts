import { useState, useCallback, useRef } from "react";
import { showToast, Toast } from "@raycast/api";
import { exec, ChildProcess } from "child_process";
import { join } from "path";
import { existsSync, mkdirSync } from "fs";
import { STORAGE_PATH, SOX_COMMAND } from "../constants";
import { AudioRecorderState } from "../types";
import { debug, error } from "../utils/logger";
import { ensureBackgroundPaths, writeStatus as writeBgStatus } from "../utils/background-task";
import { getPreferences } from "../utils/ai/transcription";

export function useAudioRecorder() {
  const [state, setState] = useState<AudioRecorderState>({
    isRecording: false,
    isPaused: false,
    duration: 0,
  });

  const recordingProcess = useRef<ChildProcess | null>(null);
  const startTime = useRef<number>(0);
  const durationInterval = useRef<NodeJS.Timeout | null>(null);

  // ç¡®ä¿éŸ³é¢‘ç›®å½•å­˜åœ¨
  const ensureAudioDirectory = (customPath?: string) => {
    const audioDir = customPath || STORAGE_PATH.AUDIO_DIR;
    if (!existsSync(audioDir)) {
      mkdirSync(audioDir, { recursive: true });
    }
    return audioDir;
  };

  // ç”ŸæˆéŸ³é¢‘æ–‡ä»¶è·¯å¾„
  const generateAudioFilePath = () => {
    const preferences = getPreferences();
    const audioDir = ensureAudioDirectory(preferences.audioSaveLocation);
    const timestamp = new Date().toISOString().replace(/[:.]/g, "-");
    return join(audioDir, `recording-${timestamp}.wav`);
  };

  // å¼€å§‹å½•éŸ³
  const startRecording = useCallback(async () => {
    try {
      debug("AudioRecorder", "ðŸ› DEBUG: startRecording() called");
      const audioFilePath = generateAudioFilePath();
      debug("AudioRecorder", "ðŸ› DEBUG: Generated audio file path", { audioFilePath });

      setState({
        isRecording: true,
        isPaused: false,
        duration: 0,
        audioFilePath,
      });
      debug("AudioRecorder", "ðŸ› DEBUG: State updated to isRecording=true");

      // æ·»åŠ å»¶è¿Ÿç¡®è®¤çŠ¶æ€æ›´æ–°å®Œæˆ
      setTimeout(() => {
        debug("AudioRecorder", "ðŸ› DEBUG: State should be updated now, checking...");
      }, 10);

      startTime.current = Date.now();

      // å¼€å§‹è®¡æ—¶
      durationInterval.current = setInterval(() => {
        const elapsed = Math.floor((Date.now() - startTime.current) / 1000);
        setState((prev) => ({ ...prev, duration: elapsed }));
      }, 100);

      // æž„å»ºSoxå‘½ä»¤ - å¯¹åŒ…å«ç©ºæ ¼çš„è·¯å¾„è¿›è¡Œå¼•å·åŒ…è£¹
      const command = [...SOX_COMMAND, `"${audioFilePath}"`].join(" ");
      debug("AudioRecorder", "Sox command", { command });

      recordingProcess.current = exec(command, (err, stdout, stderr) => {
        if (err && !err.killed) {
          error("AudioRecorder", "Recording process error", err);
          showToast({
            style: Toast.Style.Failure,
            title: "Recording failed",
            message: err.message,
          });
        } else if (err && err.killed) {
          debug("AudioRecorder", "Recording process killed normally");
        }

        if (stdout) {
          debug("AudioRecorder", "Sox stdout", { stdout });
        }
        if (stderr) {
          debug("AudioRecorder", "Sox stderr", { stderr });
        }
      });

      // æ£€æŸ¥è¿›ç¨‹æ˜¯å¦çœŸçš„å¯åŠ¨äº†
      if (recordingProcess.current && recordingProcess.current.pid) {
        debug("AudioRecorder", "Sox process started", { pid: recordingProcess.current.pid });
        try {
          ensureBackgroundPaths();
          writeBgStatus({
            status: "recording",
            pid: recordingProcess.current.pid,
            audioFilePath,
            timestamps: { startedAt: new Date().toISOString() },
          });
        } catch {}
      } else {
        error("AudioRecorder", "Failed to start Sox process");
        throw new Error("Failed to start Sox process");
      }

      await showToast({
        style: Toast.Style.Success,
        title: "Recording started",
        message: "Press Cmd+R to stop recording",
      });

      debug("AudioRecorder", "ðŸ› DEBUG: startRecording() completed successfully", {
        audioFilePath,
      });
      return audioFilePath;
    } catch (error) {
      console.error("Failed to start recording:", error);
      await showToast({
        style: Toast.Style.Failure,
        title: "Failed to start recording",
        message: error instanceof Error ? error.message : "Unknown error",
      });
      setState({
        isRecording: false,
        isPaused: false,
        duration: 0,
      });
      throw error;
    }
  }, []);

  // åœæ­¢å½•éŸ³
  const stopRecording = useCallback(async () => {
    debug("AudioRecorder", "ðŸ› DEBUG: stopRecording() called", {
      isRecording: state.isRecording,
      processExists: !!recordingProcess.current,
    });

    if (!state.isRecording || !recordingProcess.current) {
      debug(
        "AudioRecorder",
        "ðŸ› DEBUG: stopRecording() early return - not recording or no process"
      );
      return null;
    }

    try {
      // åœæ­¢è®¡æ—¶
      if (durationInterval.current) {
        clearInterval(durationInterval.current);
        durationInterval.current = null;
      }

      // ç»ˆæ­¢å½•éŸ³è¿›ç¨‹
      recordingProcess.current.kill("SIGTERM");
      recordingProcess.current = null;

      setState((prev) => ({
        ...prev,
        isRecording: false,
        isPaused: false,
      }));

      try {
        ensureBackgroundPaths();
        writeBgStatus({
          status: "stopped",
          audioFilePath: state.audioFilePath,
          timestamps: { startedAt: undefined, stoppedAt: new Date().toISOString() },
        });
      } catch {}

      await showToast({
        style: Toast.Style.Success,
        title: "Recording stopped",
        message: `Duration: ${state.duration}s`,
      });

      return state.audioFilePath;
    } catch (error) {
      console.error("Failed to stop recording:", error);
      await showToast({
        style: Toast.Style.Failure,
        title: "Failed to stop recording",
        message: error instanceof Error ? error.message : "Unknown error",
      });
      return null;
    }
  }, [state.isRecording, state.duration, state.audioFilePath]);

  // æš‚åœå½•éŸ³ (Soxä¸æ”¯æŒæš‚åœï¼Œè¿™é‡Œåªæ˜¯UIçŠ¶æ€)
  const pauseRecording = useCallback(() => {
    if (!state.isRecording || state.isPaused) {
      return;
    }

    setState((prev) => ({ ...prev, isPaused: true }));

    if (durationInterval.current) {
      clearInterval(durationInterval.current);
      durationInterval.current = null;
    }
  }, [state.isRecording, state.isPaused]);

  // æ¢å¤å½•éŸ³
  const resumeRecording = useCallback(() => {
    if (!state.isRecording || !state.isPaused) {
      return;
    }

    setState((prev) => ({ ...prev, isPaused: false }));

    // æ¢å¤è®¡æ—¶
    startTime.current = Date.now() - state.duration * 1000;
    durationInterval.current = setInterval(() => {
      const elapsed = Math.floor((Date.now() - startTime.current) / 1000);
      setState((prev) => ({ ...prev, duration: elapsed }));
    }, 100);
  }, [state.isRecording, state.isPaused, state.duration]);

  // æ ¼å¼åŒ–æ—¶é•¿
  const formatDuration = useCallback((seconds: number) => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins.toString().padStart(2, "0")}:${secs.toString().padStart(2, "0")}`;
  }, []);

  return {
    state,
    startRecording,
    stopRecording,
    pauseRecording,
    resumeRecording,
    formatDuration,
  };
}
